########## GENERAL ##########

spring.application.name=outbox-mongodb-kafka-remover


########## KAFKA ##########

spring.kafka.bootstrap-servers=${OUTBOX_REMOVER_KAFKA_BOOTSTRAP_SERVERS}

# In a production enviroment, must be the same value in all instances of that application/consumer
# For example, in Kubernetes, could be the name of Deployment
spring.kafka.consumer.group-id=${OUTBOX_REMOVER_KAFKA_CONSUMER_GROUP_ID}

# In a production enviroment, must have different value for each instance of that application/consumer.
# For example, in Kubernetes, could be the name of pod.
# If client-id is the same for all instances, each instance will produce the sames ids: "client 1", "client 2" etc.
spring.kafka.consumer.client-id=${OUTBOX_REMOVER_KAFKA_CONSUMER_CLIENT_ID}

# earliest: if reset is necessary, reprocess all messages present in Kafka in that moment.
# As this consumer is idempotent, there is no problem in reprocess duplicated messages.
spring.kafka.consumer.auto-offset-reset=earliest

# Related with spring.kafka.listener.ack-mode
spring.kafka.consumer.enable-auto-commit=false


#spring.kafka.consumer.key-deserializer=
#spring.kafka.consumer.value-deserializer=

# When LISTENING TO MULTIPLE TOPICS (which is the case of that application), the default partition distribution may not be what you expect. 
# For example, if you have three topics with five partitions each and you want to use concurrency=15, 
# you see only five active consumers, each assigned one partition from each topic, with the other 10 consumers being idle. 
# This is because the default Kafka PartitionAssignor is the RangeAssignor (see its Javadoc). 
# For this scenario, you may want to consider using the RoundRobinAssignor instead, 
# which distributes the partitions across all of the consumers. Then, each consumer is assigned one topic or partition. 
spring.kafka.consumer.properties.partition.assignment.strategy=org.apache.kafka.clients.consumer.RoundRobinAssignor

# Relates to outbox.remover.kafka.consumer.topic.pattern
# Time to refresh metadata and discover new topics that match the topic pattern
spring.kafka.consumer.properties.metadata.max.age.ms=${OUTBOX_REMOVER_KAFKA_CONSUMER_METADATA_MAX_AGE_MS}


spring.kafka.listener.type=batch

# Related with spring.kafka.consumer.enable-auto-commit
# When auto-commit=false, commit offsets when all messages in the poll() batch is processed
spring.kafka.listener.ack-mode=batch

spring.kafka.listener.poll-timeout=5000ms

# Create n consumers in a unique application instance.
#
# An ideal value depends a lot on the number of topics and partitions to be consumed, 
# as well as the number of instances of this application / consumer.
#
# For example, if there will be only 1 instance of the application, then it may be 
# interesting to increase concurrency a lot so that this single instance manages several 
# consumers and is able to process several partitions concurrently.
spring.kafka.listener.concurrency=${OUTBOX_REMOVER_KAFKA_CONSUMERS_COUNT}

outbox.remover.kafka.consumer.topic.pattern=${OUTBOX_REMOVER_KAFKA_CONSUMER_TOPIC_PATTERN}


########## MONGO ##########

# A database name in uri is used only for authentication.
# If a database is not specified, then, the driver will authenticate user to the admin database. 
# Reference: https://docs.mongodb.com/manual/reference/connection-string/
#
# Put your credentials here
#
# Expected format: mongodb://user:password@server:port/auth-database
spring.data.mongodb.uri=${OUTBOX_REMOVER_MONGODB_URI}
